{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a10da7",
   "metadata": {},
   "source": [
    "## 1. [20 pts] At a high-level, without entering into mathematical details, compare and contrast the following classifiers:\n",
    "### Perceptron (textbook's version)\n",
    "Perceptron classifies based on computed weights. It determines these weights by reading in each training value, computing the prediction, then updating the weights depending on the correctness of this prediciton.<br>\n",
    "Perceptron will converge if the classes are linearly seperable.<br>\n",
    "Perception works by creating a computed decision boundary between the classes, and focuses on minimizing misclassified classes.<br>\n",
    "Perceptron is useful for getting a quick linear boundary on a dataset.<br>\n",
    "Perceptrons can be trained online which means the data can be input one at a time and the algorithm will update the weights. SVM is unable to do this, which means in some cases, perceptron is better from a integrated systems standpoint<br>\n",
    "Perceptron is distance based, so the algorithm prefers numrical features. <br>\n",
    "The textbooks version of perceptron seems to use a linear classifier and no kernel, so this could be the fastest algorithm depending on the depth of the decision tree.\n",
    "### SVM\n",
    "Support vector machines work like Perceptron by creating a decision boundary between classes, but instead of focusing on minimizing errors, SVM tries to maximize the margin<br>\n",
    "The reason that maximizing the margin can be better than minimizing errors is there is less of a chance of overfitting.<br>\n",
    "SVM, combined with good pre-processing, is a useful model that can be deployed with high accuracy metrics.<br>\n",
    "Like Perceptron, SVM is distance based, so the algorithm prefers numerical features.\n",
    "<br>\n",
    "The speed of SVM depends on the kernel it uses, but in comparison to the other classifiers, it will take longer than perceptron and decision trees. Depending on the kernal and the amount of trees, it may be quicker than a random forest.\n",
    "### Decision Tree\n",
    "Decision Trees make classifications based on a series of binary questions. These binary questions usually result in ranges for each feature, for example petalwidth 1<x<1.5 , sepalwidth 2<x<2.5 will be classified as Setosa.<br>\n",
    "Decision trees are useful for interpreting the data. They are visual and logical, which can be good for understanding data and helping customers understand what data means.<br>\n",
    "Decision trees use entropy, so the algorithm prefers nominal features.\n",
    "<br>\n",
    "Decision trees are pretty fast and if speed is an issue, the depth can be reduced. This will affect accuracy but as I state below, accuracy is not the greatest strength of decision trees.\n",
    "### Random Forest (you have to research a bit about this classifier)\n",
    "Random forests are built from decision tress. The dataset is divided into random subsets and fed into decision trees. The output classification of the random forest is the majority vote of those decision trees. <br>\n",
    "Random forests will provide better accuracy measures than decision tress, but will take longer to train because it has to build multiple decision tress.<br>\n",
    "Like decision trees, random forests use entropy, so the algorithm prefers nominal features.\n",
    "<br>\n",
    "Both decision trees and random forests are able to classify input quickly once the algorithms are trained<br>\n",
    "#### Some comparison criterion can be, Does the method solve an optimization problem, if yes what is the cost function? Speed? Strength? Robustness? Feature type that the classifier naturally uses (e.g. based on the comparison measure, such as entropy or distance) Which one will be the first that you would try on your dataset?\n",
    "Overall, the first algorithm I would try on a dataset depends on the data itself.  If the data is numerical, then I would try SVM. Even though it will take longer than Perceptron, it is less prone to overfitting and will give more accurate metrics. This is helpful so that we can determine what preprocessing needs to be done<br>\n",
    "On the other hand, if the data is more nominal, I would choose a decision tree. Decision trees are pretty fast and I am more using it to find out information on the data, not the actual accuracy metrics. There are libraries like dtreevis that will show a graph of the decision tree, and using this we can see what the most important features might be."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a0db6",
   "metadata": {},
   "source": [
    "## 2. [20 pts] Using real datasets (can also be hypothetically constructed by yourself) define the following feature types, and give example values from your dataset. How would you represent these features in a computer program? (e.g. 32-bit integer? Floating point? String?)\n",
    "### Numerical\n",
    "Numerical feature types are features with numbers in the set -INF to INF. They can be any of the number types such as integers or floats, but floats are better because they capture decimal values and don't necesarily take longer to process.\n",
    "Below in the Numerical and Image section, you can see each of the pixel features are numerical, and they are represented by floats.\n",
    "### Nominal\n",
    "Nominal feature types are features with a finite number of categories. The categories can be represented by many data types such as text, numbers, or booleans. In a computer program, these features can either be represented as the category name itself, or an integer representing the category. In output, the category name itself will probably be more useful.\n",
    "Below in the nominal section, you can see two different ways the nominal data can be represented. There is the actual label_name, then the corresponding label_number. I also showed how to convert nominal data into integer categories using one hot encoder.\n",
    "### Text\n",
    "Text data is harder to use in machine learning algorithms. Text data is a sequence of characters and would be input as a string. In order to use it, bag of words algorithms convert these strings into a vocabulary. Using the vocabulary, the text will end up being represented by an array of booleans.\n",
    "Below in the text section, you can see a dataframe of text strings.\n",
    "### Image\n",
    "Image feature types are represented as a matrix of pixels. Images usually get flattened into an array of pixels, which are numerical values.\n",
    "Below in the Numerical and Image section, you can see images represented as an array of numerical pixels\n",
    "### Dependent variable\n",
    "Dependant feature types are features that depend on the independant variables of the data. Dependant variables are the desired classification or labels. They can be numerical or nominal. If they are nominal, it may be best to convert them to integers. \n",
    "Below in the Nominal and Dependant section, you can see label_name, label_num, and One_hot are all dependant variables with different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b52e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d983c",
   "metadata": {},
   "source": [
    "## Numerical and Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75bfedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        4.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        1.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        2.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        8.0        0.0   \n",
       "\n",
       "      pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0           0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1           0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2           0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3           0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4           0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        2.0       14.0       15.0        9.0   \n",
       "1793        0.0        0.0        6.0       16.0       14.0        6.0   \n",
       "1794        0.0        0.0        2.0        9.0       13.0        6.0   \n",
       "1795        0.0        0.0        5.0       12.0       16.0       12.0   \n",
       "1796        0.0        1.0        8.0       12.0       14.0       12.0   \n",
       "\n",
       "      pixel_7_6  pixel_7_7  \n",
       "0           0.0        0.0  \n",
       "1           0.0        0.0  \n",
       "2           9.0        0.0  \n",
       "3           0.0        0.0  \n",
       "4           0.0        0.0  \n",
       "...         ...        ...  \n",
       "1792        0.0        0.0  \n",
       "1793        0.0        0.0  \n",
       "1794        0.0        0.0  \n",
       "1795        0.0        0.0  \n",
       "1796        1.0        0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = datasets.load_digits()\n",
    "imagesDF = pd.DataFrame(images.data, columns=images.feature_names)\n",
    "imagesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438626f4",
   "metadata": {},
   "source": [
    "## Nominal and Dependant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d3840a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label_num</th>\n",
       "      <th>label_name</th>\n",
       "      <th>One_Hot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>virginica</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     label_num label_name  One_Hot  \n",
       "0            0     setosa        0  \n",
       "1            0     setosa        0  \n",
       "2            0     setosa        0  \n",
       "3            0     setosa        0  \n",
       "4            0     setosa        0  \n",
       "..         ...        ...      ...  \n",
       "145          2  virginica        2  \n",
       "146          2  virginica        2  \n",
       "147          2  virginica        2  \n",
       "148          2  virginica        2  \n",
       "149          2  virginica        2  \n",
       "\n",
       "[150 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "irisDF = pd.DataFrame(iris.data, columns=iris.feature_names) \n",
    "irisDF['label_num'] = iris.target\n",
    "irisDF['label_name'] = [iris.target_names[v] for v in iris.target]\n",
    "labelencoder = LabelEncoder()\n",
    "irisDF['One_Hot'] = labelencoder.fit_transform(irisDF['label_name'])\n",
    "irisDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4772518f",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c845d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>From: bmdelane@quads.uchicago.edu (brian manni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>From: david@terminus.ericsson.se (David Bold)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>From: dbm0000@tm0006.lerc.nasa.gov (David B. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>From: abarden@tybse1.uucp (Ann Marie Barden)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>From: leunggm@odin.control.utoronto.ca (Gary L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>From: csyphers@uafhp..uark.edu (Chris Syphers)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>From: nagle@netcom.com (John Nagle)\\nSubject: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>From: r4938585@joplin.biosci.arizona.edu (Doug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>From: jonh@david.wheaton.edu (Jonathan Hayward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>From: jimf@centerline.com (Jim Frost)\\nSubject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>From: mrh@iastate.edu (Michael R Hartman)\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Subject: Teenage acne\\nFrom: pchurch@swell.act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>From: xandor@unixg.ubc.ca (John Gilbert )\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>From: joec@hilbert.cyprs.rain.com ( Joe Cipale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>From: static@iat.holonet.net (Joe Ehrlich)\\nSu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>From: ebrandt@jarthur.claremont.edu (Eli Brand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>From: behanna@syl.nj.nec.com (Chris BeHanna)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>From: bressler@iftccu.ca.boeing.com (Rick Bres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>From:  (Sean Garrison)\\nSubject: Re: Bonilla\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>From: root@ncube.com (Operator)\\nSubject: Re: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>From: ab245@cleveland.Freenet.Edu (Sam Latonia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>From: cmeyer@bloch.Stanford.EDU (Craig Meyer)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>From: Robert Everett Brunskill &lt;rb6t+@andrew.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>From: vng@iscs.nus.sg\\nSubject: Wyse 60 Termin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>From: speedy@engr.latech.edu (Speedy Mercer)\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>From: tg@cs.toronto.edu (Tom Glinos)\\nSubject:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>From: 18084TM@msu.edu (Tom)\\nSubject: Golden &amp;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1   From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2   From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
       "3   From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
       "4   From: jcm@head-cfa.harvard.edu (Jonathan McDow...\n",
       "5   From: dfo@vttoulu.tko.vtt.fi (Foxvog Douglas)\\...\n",
       "6   From: bmdelane@quads.uchicago.edu (brian manni...\n",
       "7   From: bgrubb@dante.nmsu.edu (GRUBB)\\nSubject: ...\n",
       "8   From: holmes7000@iscsvax.uni.edu\\nSubject: WIn...\n",
       "9   From: kerr@ux1.cso.uiuc.edu (Stan Kerr)\\nSubje...\n",
       "10  From: irwin@cmptrc.lonestar.org (Irwin Arnstei...\n",
       "11  From: david@terminus.ericsson.se (David Bold)\\...\n",
       "12  From: rodc@fc.hp.com (Rod Cerkoney)\\nSubject: ...\n",
       "13  From: dbm0000@tm0006.lerc.nasa.gov (David B. M...\n",
       "14  From: jllee@acsu.buffalo.edu (Johnny L Lee)\\nS...\n",
       "15  From: mathew <mathew@mantis.co.uk>\\nSubject: R...\n",
       "16  From: ab@nova.cc.purdue.edu (Allen B)\\nSubject...\n",
       "17  From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\nS...\n",
       "18  From: ritley@uimrl7.mrl.uiuc.edu ()\\nSubject: ...\n",
       "19  From: abarden@tybse1.uucp (Ann Marie Barden)\\n...\n",
       "20  From: keith@cco.caltech.edu (Keith Allan Schne...\n",
       "21  From: leunggm@odin.control.utoronto.ca (Gary L...\n",
       "22  From: rpwhite@cs.nps.navy.mil (rpwhite)\\nSubje...\n",
       "23  From: csyphers@uafhp..uark.edu (Chris Syphers)...\n",
       "24  From: nodine@lcs.mit.edu (Mark H. Nodine)\\nSub...\n",
       "25  From: kph2q@onyx.cs.Virginia.EDU (Kenneth Hinc...\n",
       "26  From: nagle@netcom.com (John Nagle)\\nSubject: ...\n",
       "27  From: r4938585@joplin.biosci.arizona.edu (Doug...\n",
       "28  From: jonh@david.wheaton.edu (Jonathan Hayward...\n",
       "29  From: jimf@centerline.com (Jim Frost)\\nSubject...\n",
       "30  From: mrh@iastate.edu (Michael R Hartman)\\nSub...\n",
       "31  Subject: Teenage acne\\nFrom: pchurch@swell.act...\n",
       "32  From: xandor@unixg.ubc.ca (John Gilbert )\\nSub...\n",
       "33  From: ayr1@cunixa.cc.columbia.edu (Amir Y Rose...\n",
       "34  From: joec@hilbert.cyprs.rain.com ( Joe Cipale...\n",
       "35  From: dchhabra@stpl.ists.ca (Deepak Chhabra)\\n...\n",
       "36  From: static@iat.holonet.net (Joe Ehrlich)\\nSu...\n",
       "37  From: ebrandt@jarthur.claremont.edu (Eli Brand...\n",
       "38  From: behanna@syl.nj.nec.com (Chris BeHanna)\\n...\n",
       "39  From: bressler@iftccu.ca.boeing.com (Rick Bres...\n",
       "40  From:  (Sean Garrison)\\nSubject: Re: Bonilla\\n...\n",
       "41  From: root@ncube.com (Operator)\\nSubject: Re: ...\n",
       "42  From: ab245@cleveland.Freenet.Edu (Sam Latonia...\n",
       "43  From: paul@csd4.csd.uwm.edu (Paul R Krueger)\\n...\n",
       "44  From: cmeyer@bloch.Stanford.EDU (Craig Meyer)\\...\n",
       "45  From: Robert Everett Brunskill <rb6t+@andrew.c...\n",
       "46  From: vng@iscs.nus.sg\\nSubject: Wyse 60 Termin...\n",
       "47  From: speedy@engr.latech.edu (Speedy Mercer)\\n...\n",
       "48  From: tg@cs.toronto.edu (Tom Glinos)\\nSubject:...\n",
       "49  From: 18084TM@msu.edu (Tom)\\nSubject: Golden &..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = datasets.fetch_20newsgroups()\n",
    "textDF = pd.DataFrame(text.data).head(50)\n",
    "textDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8fb94",
   "metadata": {},
   "source": [
    "## 3. [20 pts] Using online resources, research and find other classifier performance metrics which are also as common as the accuracy metric. Write down the mathematical equations and the meaning of the metrics that you found.\n",
    "Some important definitions<br>\n",
    "True Positive: Actually yes and predicted yes<br>\n",
    "True Negative: Actually no and predicted no<br>\n",
    "False Positive: Actually no and predicted yes<br>\n",
    "False Negative: Actually yes and predicted no<br>\n",
    "### Accuracy\n",
    "Accuracy = $\\frac{True Positive + True Negative}{True Positive + True Negative + False Positive + False Negative}$<br>\n",
    "This finds the ration of correct predictions to the total predictions. <br>\n",
    "Good when data is balanced without skew.\n",
    "### Precision\n",
    "Precision = $\\frac{True Positive}{True Positive + False Positive}$<br>\n",
    "This finds the ratio of correct positive predictions to total positive predictions. <br>\n",
    "### Recall\n",
    "Recall = $\\frac{True Positive}{True Positive + False Negative}$<br>\n",
    "This finds the ratio of correct positive predictions to actual positives.<br>\n",
    "Accuracy, precision, and recall are usually used in tandem.\n",
    "### Logarithmic Loss\n",
    "N samples, M classes <br>\n",
    "y_ij is whether i belongs to class j<br>\n",
    "p_ij is the probability that i belongs to j<br>\n",
    "LogLoss = $\\frac{-1}{N}$$\\sum_{i=1}^{N}\\sum_{j=1}^{M}y_ij * log(p_ij)$<br>\n",
    "Logarithmic loss is good for multiple classes since it penalizes the false classifications. User sets the probability of classes.\n",
    "### Confusion Matrix\n",
    "Creates a matrix showing the true results of the model which is very good for the absolute performance of the algorithm.<br>\n",
    "Table shows True Positives, True Negatives, False Positives, and False Negatives.\n",
    "### F1 Score\n",
    "F1 = 2*$\\frac{precision*recall}{precision+recall}$<br>\n",
    "F1 score is realiant on both precision and recall, so it is gauging the number of correct positive predictions to both total positive predictions and actual prositives. F1 score can also be weigthed if precision is more important than recall in a problem or vice versa.\n",
    "### Mean Squared Error\n",
    "MSE = $\\frac{1}{N}$$\\sum_{i=1}^{N}{(xi-\\hat{xi})}^2$<br>\n",
    "MSE is the average of the distance between the original value and predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f118945",
   "metadata": {},
   "source": [
    "## 4. [40 pts] Implement a correlation program from scratch to look at the correlations between the features of Admission_Predict.csv dataset file (not provided, you have to download it by yourself by following the instructions in the module Jupyter notebook). Display the correlation matrix where each row and column are the features, which should be an 8 by 8 matrix (should we use 'Serial no'?). You can use pandas DataFrame.corr() to verify correctness of yours.\n",
    "### Remember, you are not allowed to used numpy methods like mean(), etc. Observe that the diagonal of this matrix should have all 1's and explain why? Since the last column can be used as the target (dependent) variable, what do you think about the correlations between all the variables? Which variable should be the most important for prediction of 'Chance of Admit'?\n",
    "The diagonals will all be 1 because the covariance of the same column will just be the standard deviation squared.  If we look at the formulas, they are nearly the same, except covariance accounts for both x and y. If x and y are equal, then this will jsut be squared. Therefore, the covariance is the standard deviation squared, making the correlation 1.<br>\n",
    "The correlation between features and the dependant variable means that that feature would be an effective variable in predicting Chance of Admit. CGPA has the highest correlation, so this would be most important for the prediction of Chance of Admit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c7312d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions = pd.read_csv('Admission_Predict.csv')\n",
    "admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debe5ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097526</td>\n",
       "      <td>-0.147932</td>\n",
       "      <td>-0.169948</td>\n",
       "      <td>-0.166932</td>\n",
       "      <td>-0.088221</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.042336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>-0.097526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>-0.147932</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.791594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>-0.169948</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.166932</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>-0.088221</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.669889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.873289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.042336</td>\n",
       "      <td>0.802610</td>\n",
       "      <td>0.791594</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.669889</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial No.  GRE Score  TOEFL Score  University Rating  \\\n",
       "Serial No.           1.000000  -0.097526    -0.147932          -0.169948   \n",
       "GRE Score           -0.097526   1.000000     0.835977           0.668976   \n",
       "TOEFL Score         -0.147932   0.835977     1.000000           0.695590   \n",
       "University Rating   -0.169948   0.668976     0.695590           1.000000   \n",
       "SOP                 -0.166932   0.612831     0.657981           0.734523   \n",
       "LOR                 -0.088221   0.557555     0.567721           0.660123   \n",
       "CGPA                -0.045608   0.833060     0.828417           0.746479   \n",
       "Research            -0.063138   0.580391     0.489858           0.447783   \n",
       "Chance of Admit      0.042336   0.802610     0.791594           0.711250   \n",
       "\n",
       "                        SOP      LOR       CGPA  Research  Chance of Admit   \n",
       "Serial No.        -0.166932 -0.088221 -0.045608 -0.063138          0.042336  \n",
       "GRE Score          0.612831  0.557555  0.833060  0.580391          0.802610  \n",
       "TOEFL Score        0.657981  0.567721  0.828417  0.489858          0.791594  \n",
       "University Rating  0.734523  0.660123  0.746479  0.447783          0.711250  \n",
       "SOP                1.000000  0.729593  0.718144  0.444029          0.675732  \n",
       "LOR                0.729593  1.000000  0.670211  0.396859          0.669889  \n",
       "CGPA               0.718144  0.670211  1.000000  0.521654          0.873289  \n",
       "Research           0.444029  0.396859  0.521654  1.000000          0.553202  \n",
       "Chance of Admit    0.675732  0.669889  0.873289  0.553202          1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e026d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSeries(series):\n",
    "    sum = 0\n",
    "    length = len(series)\n",
    "    for index, value in series.items():\n",
    "        sum = sum + value\n",
    "    return sum/length\n",
    "\n",
    "def stdevSeries(series):\n",
    "    mean = meanSeries(series)\n",
    "    #devs = [(value - mean) for index, value in series.items()]\n",
    "    devs = []\n",
    "    for index, value in series.items():\n",
    "        devs.append((value-mean) ** 2)\n",
    "    sum = 0\n",
    "    for value in devs:\n",
    "        sum = sum + value\n",
    "    st = math.sqrt(sum/(len(series)-1))\n",
    "    return st\n",
    "\n",
    "def covar(x,y):\n",
    "    #cov(X, Y) = (sum (x - mean(X)) * (y - mean(Y)) ) * 1/(n-1)\n",
    "    sum = 0\n",
    "    meanX = meanSeries(x)\n",
    "    meanY = meanSeries(y)\n",
    "    distance = []\n",
    "    for i in range(len(x)):\n",
    "        distance.append((x[i]-meanX)*(y[i]-meanY))\n",
    "    for value in distance:\n",
    "        sum = sum + value\n",
    "    return sum/(len(x)-1)\n",
    "\n",
    "def corr(x,y):\n",
    "    return covar(x, y)/(stdevSeries(x) * stdevSeries(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b791f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Serial No.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.097526</td>\n",
       "      <td>-0.147932</td>\n",
       "      <td>-0.169948</td>\n",
       "      <td>-0.166932</td>\n",
       "      <td>-0.088221</td>\n",
       "      <td>-0.045608</td>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.042336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRE Score</th>\n",
       "      <td>-0.097526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.802610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOEFL Score</th>\n",
       "      <td>-0.147932</td>\n",
       "      <td>0.835977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.791594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>University Rating</th>\n",
       "      <td>-0.169948</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>0.695590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.711250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOP</th>\n",
       "      <td>-0.166932</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>0.657981</td>\n",
       "      <td>0.734523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.675732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOR</th>\n",
       "      <td>-0.088221</td>\n",
       "      <td>0.557555</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.660123</td>\n",
       "      <td>0.729593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.669889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGPA</th>\n",
       "      <td>-0.045608</td>\n",
       "      <td>0.833060</td>\n",
       "      <td>0.828417</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.718144</td>\n",
       "      <td>0.670211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>0.873289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Research</th>\n",
       "      <td>-0.063138</td>\n",
       "      <td>0.580391</td>\n",
       "      <td>0.489858</td>\n",
       "      <td>0.447783</td>\n",
       "      <td>0.444029</td>\n",
       "      <td>0.396859</td>\n",
       "      <td>0.521654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chance of Admit</th>\n",
       "      <td>0.042336</td>\n",
       "      <td>0.802610</td>\n",
       "      <td>0.791594</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.669889</td>\n",
       "      <td>0.873289</td>\n",
       "      <td>0.553202</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Serial No.  GRE Score  TOEFL Score  University Rating  \\\n",
       "Serial No.           1.000000  -0.097526    -0.147932          -0.169948   \n",
       "GRE Score           -0.097526   1.000000     0.835977           0.668976   \n",
       "TOEFL Score         -0.147932   0.835977     1.000000           0.695590   \n",
       "University Rating   -0.169948   0.668976     0.695590           1.000000   \n",
       "SOP                 -0.166932   0.612831     0.657981           0.734523   \n",
       "LOR                 -0.088221   0.557555     0.567721           0.660123   \n",
       "CGPA                -0.045608   0.833060     0.828417           0.746479   \n",
       "Research            -0.063138   0.580391     0.489858           0.447783   \n",
       "Chance of Admit      0.042336   0.802610     0.791594           0.711250   \n",
       "\n",
       "                        SOP      LOR       CGPA  Research  Chance of Admit   \n",
       "Serial No.        -0.166932 -0.088221 -0.045608 -0.063138          0.042336  \n",
       "GRE Score          0.612831  0.557555  0.833060  0.580391          0.802610  \n",
       "TOEFL Score        0.657981  0.567721  0.828417  0.489858          0.791594  \n",
       "University Rating  0.734523  0.660123  0.746479  0.447783          0.711250  \n",
       "SOP                1.000000  0.729593  0.718144  0.444029          0.675732  \n",
       "LOR                0.729593  1.000000  0.670211  0.396859          0.669889  \n",
       "CGPA               0.718144  0.670211  1.000000  0.521654          0.873289  \n",
       "Research           0.444029  0.396859  0.521654  1.000000          0.553202  \n",
       "Chance of Admit    0.675732  0.669889  0.873289  0.553202          1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrPD = pd.DataFrame(0, index=admissions.columns, columns=admissions.columns)\n",
    "corrCOL = []\n",
    "for col in admissions.columns:\n",
    "    for index in range(len(admissions.columns)):\n",
    "        corrCOL.append(corr(admissions[col], admissions[admissions.columns[index]]).round(6))\n",
    "    corrPD[col] = corrCOL\n",
    "    corrCOL=[]\n",
    "corrPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ab720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
